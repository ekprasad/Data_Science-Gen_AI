{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "O3GlqriYVaqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is a parameter?**  \n",
        "\n",
        "Ans - A parameter is a variable in a machine learning model that is learned from the training data. Examples include weights in a linear regression model or connection strengths in a neural network.\n",
        "\n",
        "**2. What is correlation?What does negative correlation mean?**  \n",
        "\n",
        "Ans - Correlation is a statistical measure that describes the degree to which two variables move in relation to each other.\n",
        "Negative correlation means that as one variable increases, the other decreases. For example, as the price of a product increases, its demand may decrease.\n",
        "\n",
        "**3. Define Machine Learning. What are the main components in Machine Learning?**  \n",
        "Ans - **Machine Learning (ML)** is a subset of artificial intelligence that enables computers to learn from data and make predictions without being explicitly programmed.  \n",
        "   * **Main components:**  \n",
        "     1. **Data** - The input that is used for training and testing.  \n",
        "     2. **Features** - Variables used to make predictions.  \n",
        "     3. **Model** - The algorithm that learns from data.  \n",
        "     4. **Loss Function** - Measures how well the model predicts outcomes.  \n",
        "     5. **Optimization Algorithm** - Adjusts parameters to minimize the loss.  \n",
        "\n",
        "**4. How does loss value help in determining whether the model is good or not?**  \n",
        "Ans - A lower loss value indicates that the model's predictions are close to the actual values, suggesting better performance.\n",
        "\n",
        "**5. What are continuous and categorical variables?**  \n",
        "\n",
        "Ans-  Continuous and Categorical variables:\n",
        "   * **Continuous variables**: Numeric values that can take any number within a range (e.g., height, temperature).  \n",
        "   * **Categorical variables**: Discrete values that represent categories (e.g., colors, gender, product types).\n",
        "\n",
        "**6. How do we handle categorical variables in Machine Learning? What are the common techniques?**  \n",
        "\n",
        "Ans - Handling categorical variables in ML involves converting them into numerical form. Common techniques include:  \n",
        "\n",
        "1. **One-Hot Encoding** - Creates binary columns for each category (best for nominal data).  \n",
        "2. **Label Encoding** - Assigns unique integers to categories (useful for ordinal data).  \n",
        "3. **Ordinal Encoding** - Maps categories to ordered numbers (for ordinal variables).  \n",
        "4. **Frequency Encoding** - Replaces categories with their frequency count.  \n",
        "5. **Target Encoding** - Replaces categories with mean of target variable (useful for predictive models).  \n",
        "6. **Binary Encoding** - Converts categories into binary format (reduces dimensionality).  \n",
        "\n",
        "**7. What do you mean by training and testing a dataset?**  \n",
        "\n",
        "Ans - Training and testing a dataset simply means-\n",
        "   * **Training dataset**: Used to train the machine learning model.  \n",
        "   * **Testing dataset**: Used to evaluate the performance of the trained model.\n",
        "\n",
        "**8. What is sklearn.preprocessing?**  \n",
        "\n",
        "Ans - It is a module in **scikit-learn** that provides functions for data preprocessing, including scaling, encoding, and normalization.\n",
        "\n",
        "**9. What is a Test set?**  \n",
        "\n",
        "Ans - A test set is a portion of the dataset used to evaluate a model's performance after training.\n",
        "\n",
        "**10. How do we split data for model fitting (training and testing) in Python?**\n",
        "\n",
        "Ans - In Python, we typically split data into training and testing sets using train_test_split from sklearn.model_selection. This ensures our model is trained on one part and tested on unseen data.\n",
        "  \n",
        "Syntax:\n",
        "\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "Example:\n",
        "\n",
        "    from sklearn.model_selection import train_test_split  \n",
        "    # Sample data  \n",
        "    X = [[1], [2], [3], [4], [5]]  # Features  \n",
        "    y = [0, 1, 0, 1, 0]  # Target  \n",
        "\n",
        "    # Split into 80% training, 20% testing  \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
        "\n",
        "    print(X_train, X_test, y_train, y_test)\n",
        "\n",
        "**How do you approach a Machine Learning problem?[Qno is not given]**  \n",
        "\n",
        "Ans - Approaching a Machine Learning problem involves a structured workflow. Here's a simple step-by-step process:  \n",
        "\n",
        "**1. Understand the Problem**  \n",
        "   * Define the objective (e.g., classification, regression).  \n",
        "   * Identify key constraints and success metrics.  \n",
        "\n",
        "**2. Collect and Explore Data**  \n",
        "   * Gather data from reliable sources.  \n",
        "   * Perform **Exploratory Data Analysis (EDA)** (visualization, summary statistics).  \n",
        "\n",
        "**3. Data Preprocessing**  \n",
        "   * Handle missing values.  \n",
        "   * Encode categorical variables.  \n",
        "   * Normalize/scale numerical features.  \n",
        "   * Split data into train and test sets.  \n",
        "\n",
        "**4. Choose a Model**  \n",
        "   * Select a baseline algorithm (e.g., Logistic Regression, Decision Trees).  \n",
        "   * Try more advanced models (Random Forest, XGBoost, Neural Networks).  \n",
        "\n",
        "**5. Train and Tune the Model**  \n",
        "   * Fit the model on training data.  \n",
        "   * Optimize hyperparameters (GridSearch, RandomSearch).\n",
        "\n",
        "**6. Evaluate Performance**  \n",
        "   * Use metrics like Accuracy, RMSE, F1-score, etc.  \n",
        "   * Perform cross-validation to check generalization.  \n",
        "\n",
        "**7. Deploy and Monitor**  \n",
        "   * Deploy the model to production.  \n",
        "   * Continuously monitor performance and update as needed.  \n",
        "\n",
        "**11. Why do we have to perform EDA before fitting a model to the data?**\n",
        "\n",
        "Ans - To understand the data distribution, detect missing values, outliers, and correlations, and make informed decisions about feature selection.\n",
        "\n",
        "**12. What is correlation?**\n",
        "\n",
        "Ans - **[Repeated Quesation same as Q2.]**\n",
        "\n",
        "**13. What does negative correlation mean?**\n",
        "\n",
        "Ans - **[Repeated Quesation same as Q2.]**\n",
        "\n",
        "**14. How can you find correlation between variables in Python?**  \n",
        "\n",
        "Ans - We can find the correlation between variables in Python using **Pandas** and  **Seaborn(For Visualization)**\n",
        "\n",
        "**Using Pandas .corr()** -  Default method is Pearson correlation. Use data.corr(method='spearman') for Spearman correlation.\n",
        "\n",
        "Example:\n",
        "    import pandas as pd  \n",
        "    correlation_matrix = df.corr()  \n",
        "    print(correlation_matrix)\n",
        "\n",
        "**15. What is causation? Explain difference between correlation and causation with an example.**  \n",
        "\n",
        "Ans-  Causation means that one variable directly influences another.\n",
        "\n",
        "**Difference between correlation and causation:**  \n",
        "* Causation (or causality) means that one event directly causes another.\n",
        "* Correlation means that two variables move together but may not have a direct cause-and-effect relationship.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "* **Correlation:** Ice cream sales and drowning rates are correlated they increase together in summer.\n",
        "→ But ice cream does not cause drowning. Instead, hot weather influences both.\n",
        "\n",
        "* **Causation:** Smoking causes lung cancer.\n",
        "→ There is a direct cause-and-effect relationship.\n",
        "     \n",
        "**16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**  \n",
        "\n",
        "Ans - An optimizer is an algorithm  that adjusts the model's parameters (weights and biases) to minimize the loss. It helps improve model accuracy by optimizing how the model learns from data.\n",
        "\n",
        "**Types  of optimizers:**  \n",
        "* **Gradient Descent** - Adjusts weights using gradients.  \n",
        "* **Adam Optimizer** - Combines momentum and adaptive learning rate.  \n",
        "* **RMSprop** - Suitable for non-stationary objectives.  \n",
        "* Gradient Descent (GD) - Updates weights in the direction of the steepest loss decrease.\n",
        "Example: Batch GD computes updates using the whole dataset.\n",
        "* Stochastic Gradient Descent (SGD) - Updates weights for each data point, making it faster but noisy.\n",
        "Example: Used in online learning.\n",
        "* Adam (Adaptive Moment Estimation) - Combines Momentum and RMSProp for efficient learning.\n",
        "Example: Used in Neural Networks (default optimizer in TensorFlow/Keras).\n",
        "* RMSProp (Root Mean Square Propagation) - Adjusts learning rates based on past gradients to avoid overshooting.\n",
        "Example: Works well for RNNs.\n",
        "\n",
        "Example in Python (Adam Optimizer in TensorFlow)\n",
        "\n",
        "    from tensorflow.keras.optimizers import Adam  \n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "**17. What is sklearn.linear_model?**  \n",
        "\n",
        "Ans - A module in `scikit-learn` that provides linear models like Linear Regression and Logistic Regression.\n",
        "\n",
        "**18. What does model.fit() do? What arguments must be given?**  \n",
        "\n",
        "Ans - model.fit() is used in TensorFlow/Keras to train a machine learning model. It:\n",
        "* Feeds training data (features & labels) into the model.\n",
        "* Performs forward & backward propagation to adjust weights.\n",
        "* Optimizes the model using a loss function and optimizer.\n",
        "\n",
        "Syntax:\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "**Required Arguments:**  \n",
        "* `X_train`: Features(Input training data).  \n",
        "* `y_train`: Target values for training\n",
        "* epochs : Number of times the model sees the data.\n",
        "* batch_size : Number of samples per gradient update.\n",
        "\n",
        "**19. What does model.predict() do? What arguments must be given?**  \n",
        "\n",
        "Ans - The `model.predict()` function is used to generate predictions from a trained model based on new input data.\n",
        "\n",
        "**Required Arguments:**  \n",
        "* `X_test`: Test features  \n",
        "\n",
        "**20.  What are continuous and categorical variables?**\n",
        "\n",
        " Ans - **[Repeated Quesation same as Q5.]**\n",
        "\n",
        "**21. What is feature scaling? How does it help in Machine Learning?**  \n",
        "\n",
        "Ans-  Feature scaling is a technique used in Machine Learning to standardize the range of independent variables (features) in a dataset. It ensures that all features have comparable scales, preventing certain features from dominating others due to their larger numerical ranges.\n",
        "\n",
        "Feature scaling helps in Machine Learning by:  \n",
        "\n",
        "1. **Faster Convergence** - Gradient-based algorithms (e.g., Gradient Descent) work efficiently with scaled data.  \n",
        "2. **Improved Accuracy** - Distance-based models (e.g., k-NN, K-Means, SVM) perform better when features have similar scales.  \n",
        "3. **Prevents Bias** - Ensures no single feature dominates due to larger numerical values.  \n",
        "4. **Better Model Interpretation** - Standardized features improve visualization and comparison.\n",
        "\n",
        "**22. How do we perform scaling in Python?**  \n",
        "\n",
        "Ans- can perform feature scaling in Python using scikit-learn. The two common methods are:\n",
        "\n",
        "**1. Min-Max Scaling (Normalization) :** Scales values to a fixed range (usually 0 to 1).  \n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "```\n",
        "\n",
        "**2. Standardization (Z-score Normalization):**Scales data to have **mean = 0** and **standard deviation = 1**.  \n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "```\n",
        "\n",
        "**23. What is sklearn.preprocessing?**  \n",
        "Ans- **REPEATED QUESTION SAME AS Question 8**.\n",
        "\n",
        "It is a module in **scikit-learn** that provides functions for data preprocessing, including scaling, encoding, and normalization.\n",
        "\n",
        "**24. How do we split data for model fitting (training and testing) in Python?**  \n",
        "Ans - **REPEATED QUESTION SAME AS Question 10**\n",
        "\n",
        "**25. Explain data encoding?**  \n",
        "\n",
        "Ans - Data encoding transforms categorical variables into numerical format for machine learning models.\n",
        "\n",
        "**Types of Data Encoding:**\n",
        "1. One-hot encoding  \n",
        "* Converts categories into binary columns.\n",
        "\n",
        "* Used for nominal data (where order does not matter).\n",
        "2. Label encoding\n",
        "* Converts categories into integer values.\n",
        "* Used for ordinal data (where order matters).\n",
        "\n",
        "3. Ordinal encoding\n",
        "* Assigns numeric values based on order (like label encoding but considering rank).\n",
        "* used when categorical variables have a meaningful order or ranking, but the differences between them are not necessarily uniform."
      ],
      "metadata": {
        "id": "RB4XEtvKVbIf"
      }
    }
  ]
}